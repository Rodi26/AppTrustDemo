name: Promote to QA

on:
  workflow_dispatch:
    inputs:
      promote_to_qa:
        description: 'Promote to QA environment'
        required: false
        default: true
        type: boolean

jobs:
  promote-to-qa:
    name: Promote to QA and run E2E tests
    runs-on: ubuntu-latest
    env:
      JFROG_CLI_KEY_ALIAS: ${{ vars.JFROG_CLI_KEY_ALIAS }}
      JFROG_CLI_SIGNING_KEY: ${{ secrets.JFROG_CLI_SIGNING_KEY }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup JFrog CLI
      uses: jfrog/setup-jfrog-cli@v4
      with:
        version: latest
      env:
        JF_URL: ${{ vars.JF_URL }}
        JF_USER: ${{ vars.JF_USER }}
        JF_ACCESS_TOKEN: ${{ secrets.JF_ACCESS_TOKEN }}
    
    - name: Get latest DEV release bundle version
      id: get-latest-dev-version
      run: |
        # Fetch promotion records from Artifactory API
        PROMOTION_RESPONSE=$(curl -s -X GET \
          -H "Authorization: Bearer ${{ secrets.JF_ACCESS_TOKEN }}" \
          "${{ vars.JF_URL }}/lifecycle/api/v2/promotion/records/quotopia")

        # Filter for environment "DEV", sort by "created" field in descending order, and get the first one
        LATEST_DEV_VERSION=$(echo "$PROMOTION_RESPONSE" | \
          jq -r '.promotions | map(select(.environment == "DEV")) | sort_by(.created) | reverse | .[0].release_bundle_version')
        
        echo "latest_dev_version=$LATEST_DEV_VERSION" >> $GITHUB_OUTPUT
        echo "Found latest DEV release bundle version: $LATEST_DEV_VERSION"
    
    - name: Promote to QA
      if: ${{ inputs.promote_to_qa == 'true' }}
      run: |
        LATEST_DEV_VERSION="${{ steps.get-latest-dev-version.outputs.latest_dev_version }}"
        
        echo "ğŸš€ Promoting release bundle quotopia version $LATEST_DEV_VERSION from DEV to QA..."
        
        # Promote the release bundle from DEV to QA
        jf release-bundle-promote quotopia $LATEST_DEV_VERSION QA
        
        if [ $? -eq 0 ]; then
          echo "âœ… Successfully promoted quotopia version $LATEST_DEV_VERSION to QA"
          
          # Create a link to the QA release bundle
          QA_LINK="${{ vars.JF_URL }}/ui/artifactory/lifecycle?bundleName=quotopia&releaseBundleVersion=$LATEST_DEV_VERSION&repositoryKey=release-bundles-v2&activeKanbanTab=promotion"
          echo "ğŸ¥¡ QA Release Bundle: [quotopia:$LATEST_DEV_VERSION]($QA_LINK)" >> $GITHUB_STEP_SUMMARY
          
          # Store the version for the E2E test job
          echo "LATEST_QA_VERSION=$LATEST_DEV_VERSION" >> $GITHUB_ENV
        else
          echo "âŒ Failed to promote quotopia version $LATEST_DEV_VERSION to QA"
          exit 1
                fi

    - name: Set QA version (when promotion is skipped)
      if: ${{ inputs.promote_to_qa != 'true' }}
      run: |
        LATEST_DEV_VERSION="${{ steps.get-latest-dev-version.outputs.latest_dev_version }}"
        echo "ğŸ“‹ Using DEV version $LATEST_DEV_VERSION for QA testing (no promotion)"
        echo "LATEST_QA_VERSION=$LATEST_DEV_VERSION" >> $GITHUB_ENV
      
    - name: Cache npm dependencies
      uses: actions/cache@v4
      with:
        path: |
          e2e-tests/node_modules
          ~/.npm
        key: ${{ runner.os }}-npm-${{ hashFiles('e2e-tests/package-lock.json') }}
        restore-keys: |
          ${{ runner.os }}-npm-

    - name: Login to Docker Registry
      run: |
        echo "ğŸ” Logging into JFrog Artifactory Docker registry..."
        echo "Registry: ${{ vars.JF_URL }}"
        echo ${{ secrets.JF_ACCESS_TOKEN }} | docker login -u ${{ vars.JF_USER }} --password-stdin ${{ vars.JF_URL }}
        echo "âœ… Successfully logged into Docker registry"
        
    - name: Get Docker images from QA repository
      id: get-images
      run: |
        # Get the latest QA version
        LATEST_QA_VERSION="${{ env.LATEST_QA_VERSION }}"
        echo "Testing with QA version: $LATEST_QA_VERSION"
        
        # Get Docker image tags from QA repository using AQL with better error handling
        echo "ğŸ” Searching for quote service images..."
        QUOTE_RESPONSE=$(curl -s -X POST \
          -H "Authorization: Bearer ${{ secrets.JF_ACCESS_TOKEN }}" \
          -H "Content-Type: text/plain" \
          -d 'items.find({"repo": "commons-qa-docker-local", "name": "list.manifest.json", "path": {"$match": "quoteofday/*"}}).sort({"$desc": ["created"]}).limit(1)' \
            "${{ vars.JF_URL }}/artifactory/api/search/aql")
        
        echo "Quote API Response: $QUOTE_RESPONSE"
        
        if [ -z "$QUOTE_RESPONSE" ] || [ "$QUOTE_RESPONSE" = "null" ]; then
          echo "âŒ No quote service images found in QA repository"
          exit 1
        fi
        
        QUOTE_IMAGE_TAG=$(echo "$QUOTE_RESPONSE" | jq -r '.results[0].path | split("/") | .[1] // empty')
        
        if [ -z "$QUOTE_IMAGE_TAG" ]; then
          echo "âŒ Failed to extract quote image tag from response"
          echo "Response: $QUOTE_RESPONSE"
          exit 1
        fi
        
        echo "âœ… Found quote service image tag: $QUOTE_IMAGE_TAG"
        
        echo "ğŸ” Searching for translation service images..."
        TRANSLATION_RESPONSE=$(curl -s -X POST \
          -H "Authorization: Bearer ${{ secrets.JF_ACCESS_TOKEN }}" \
          -H "Content-Type: text/plain" \
          -d 'items.find({"repo": "commons-qa-docker-local", "name": "list.manifest.json", "path": {"$match": "ai-translate/*"}}).sort({"$desc": ["created"]}).limit(1)' \
            "${{ vars.JF_URL }}/artifactory/api/search/aql")
        
        echo "Translation API Response: $TRANSLATION_RESPONSE"
        
        if [ -z "$TRANSLATION_RESPONSE" ] || [ "$TRANSLATION_RESPONSE" = "null" ]; then
          echo "âŒ No translation service images found in QA repository"
          exit 1
        fi
        
        TRANSLATION_IMAGE_TAG=$(echo "$TRANSLATION_RESPONSE" | jq -r '.results[0].path | split("/") | .[1] // empty')
        
        if [ -z "$TRANSLATION_IMAGE_TAG" ]; then
          echo "âŒ Failed to extract translation image tag from response"
          echo "Response: $TRANSLATION_RESPONSE"
          exit 1
        fi
        
        echo "âœ… Found translation service image tag: $TRANSLATION_IMAGE_TAG"

        echo "quote_image_tag=$QUOTE_IMAGE_TAG" >> $GITHUB_OUTPUT
        echo "translation_image_tag=$TRANSLATION_IMAGE_TAG" >> $GITHUB_OUTPUT
        
        echo "Quote service image: evidencetrial.jfrog.io/commons-qa-docker-local/quoteofday:$QUOTE_IMAGE_TAG" >> $GITHUB_STEP_SUMMARY
        echo "Translation service image: evidencetrial.jfrog.io/commons-qa-docker-local/ai-translate:$TRANSLATION_IMAGE_TAG" >> $GITHUB_STEP_SUMMARY
        
    - name: Generate E2E test Docker Compose file
      run: |
        # Set environment variables for template substitution
        export QUOTE_IMAGE_TAG="${{ steps.get-images.outputs.quote_image_tag }}"
        export TRANSLATION_IMAGE_TAG="${{ steps.get-images.outputs.translation_image_tag }}"
        
        # Substitute variables in the template
        envsubst < e2e-tests/docker-compose.yml.template > e2e-test-compose.yml
        
        # Display the generated file for debugging
        echo "Generated Docker Compose file:"
        cat e2e-test-compose.yml
        
    - name: Run E2E tests 
      run: |
        # Start services and run tests with optimized settings
        echo "ğŸš€ Starting optimized E2E tests..."
        
        # Pull images in parallel for faster startup
        docker pull evidencetrial.jfrog.io/commons-qa-docker-local/quoteofday:${{ steps.get-images.outputs.quote_image_tag }} &
        docker pull evidencetrial.jfrog.io/commons-qa-docker-local/ai-translate:${{ steps.get-images.outputs.translation_image_tag }} &
        wait
        
        # Start services with optimized health checks
        docker compose -f e2e-test-compose.yml up --abort-on-container-exit
        
        # Check if tests passed
        if [ $? -eq 0 ]; then
          echo "âœ… E2E tests completed successfully"
        else
          echo "âŒ E2E tests failed"
          exit 1
        fi
        
    - uses: mxschmitt/action-tmate@v3
    
    - name: Convert Cypress results to Markdown
      run: |
        echo "ğŸ“„ Converting Cypress results to Markdown report..."
        
        # Debug: Check what files exist in e2e-tests directory
        echo "ğŸ” Checking e2e-tests directory contents:"
        ls -la e2e-tests/
        
        # Check if mochawesome combined report exists
        if [ -f "e2e-tests/cypress/results/combined-report.json" ]; then
          echo "âœ… Found mochawesome combined report"
          
          # Show file size and first few lines for debugging
          echo "ğŸ“Š Combined report size: $(wc -c < e2e-tests/cypress/results/combined-report.json) bytes"
          echo "ğŸ“‹ First 10 lines of combined report:"
          head -10 e2e-tests/cypress/results/combined-report.json
          
          # Navigate to e2e-tests directory and run conversion
          cd e2e-tests
          
          # Run the conversion script with the combined report
          if ./convert-cypress-report.sh cypress/results/combined-report.json cypress-report.md; then
            echo "âœ… Markdown report generated successfully"
            
            # Copy the report to the workspace root for easy access
            cp cypress-report.md ../cypress-e2e-report.md
            
            # Display report summary
            echo "ğŸ“Š Report Summary:"
            head -20 cypress-report.md
            
            # Upload the markdown report as an artifact
            echo "ğŸ“¤ Markdown report saved as: cypress-e2e-report.md"
          else
            echo "âŒ Failed to generate markdown report"
            exit 1
          fi
        else
          echo "âš ï¸  No mochawesome combined report found, checking for individual reports..."
          echo "ğŸ” Checking for any result files:"
          find e2e-tests/ -name "*results*" -type f 2>/dev/null || echo "No result files found"
          
          # Try to merge individual mochawesome reports if they exist
          if [ -d "e2e-tests/cypress/results/mochawesome" ] && [ "$(ls -A e2e-tests/cypress/results/mochawesome)" ]; then
            echo "ğŸ”„ Found individual mochawesome reports, merging them..."
            cd e2e-tests
            npx mochawesome-merge cypress/results/mochawesome/*.json > cypress/results/combined-report.json
            
            if [ -f "cypress/results/combined-report.json" ]; then
              echo "âœ… Successfully merged individual reports"
              
              # Run the conversion script with the newly merged report
              if ./convert-cypress-report.sh cypress/results/combined-report.json cypress-report.md; then
                echo "âœ… Markdown report generated successfully"
                cp cypress-report.md ../cypress-e2e-report.md
                echo "ğŸ“¤ Markdown report saved as: cypress-e2e-report.md"
              else
                echo "âŒ Failed to generate markdown report"
                exit 1
              fi
            else
              echo "âŒ Failed to merge individual reports"
              exit 1
            fi
          else
            # Create a simple markdown report indicating no results
            echo "# Cypress E2E Test Report" > cypress-e2e-report.md
            echo "" >> cypress-e2e-report.md
            echo "## ğŸ“Š Test Summary" >> cypress-e2e-report.md
            echo "" >> cypress-e2e-report.md
            echo "No test results were found. This could indicate:" >> cypress-e2e-report.md
            echo "- Tests did not run" >> cypress-e2e-report.md
            echo "- Results file was not generated" >> cypress-e2e-report.md
            echo "- Results file is in a different location" >> cypress-e2e-report.md
            echo "" >> cypress-e2e-report.md
            echo "## ğŸ“ˆ Test Results Overview" >> cypress-e2e-report.md
            echo "" >> cypress-e2e-report.md
            echo "**Status:** âš ï¸ No Results Available" >> cypress-e2e-report.md
            echo "" >> cypress-e2e-report.md
            echo "---" >> cypress-e2e-report.md
            echo "" >> cypress-e2e-report.md
            echo "*Report generated on $(date)*" >> cypress-e2e-report.md
            echo "ğŸ“„ Created placeholder markdown report"
          fi
        fi

    - name: Create evidence from the e2e test results
      run: |
        # Debug: Check what files exist in e2e-tests directory
        echo "ğŸ” Checking e2e-tests directory contents:"
        ls -la e2e-tests/
        
        # Check if mochawesome combined report exists and validate JSON
        if [ -f "e2e-tests/cypress/results/combined-report.json" ]; then
          echo "âœ… Mochawesome combined report found"
          
          # Validate the JSON
          if jq empty e2e-tests/cypress/results/combined-report.json 2>/dev/null; then
            echo "âœ… Valid JSON found"
            cp e2e-tests/cypress/results/combined-report.json cypress-results.json
          else
            echo "âŒ Invalid JSON in combined report"
            echo "ğŸ“‹ File contents:"
            cat e2e-tests/cypress/results/combined-report.json
            exit 1
          fi
        else
          echo "âŒ Mochawesome combined report not found"
          echo "ğŸ” Checking for any result files:"
          find e2e-tests/ -name "*results*" -type f 2>/dev/null || echo "No result files found"
          
          # Try to merge individual mochawesome reports if they exist
          if [ -d "e2e-tests/cypress/results/mochawesome" ] && [ "$(ls -A e2e-tests/cypress/results/mochawesome)" ]; then
            echo "ğŸ”„ Found individual mochawesome reports, merging them..."
            cd e2e-tests
            npx mochawesome-merge cypress/results/mochawesome/*.json > cypress/results/combined-report.json
            
            if [ -f "cypress/results/combined-report.json" ]; then
              echo "âœ… Successfully merged individual reports"
              cd ..
              
              # Validate the merged JSON
              if jq empty e2e-tests/cypress/results/combined-report.json 2>/dev/null; then
                echo "âœ… Valid JSON created from merged reports"
                cp e2e-tests/cypress/results/combined-report.json cypress-results.json
              else
                echo "âŒ Invalid JSON in merged report"
                exit 1
              fi
            else
              echo "âŒ Failed to merge individual reports"
              exit 1
            fi
          else
            echo "âŒ No mochawesome reports found"
            exit 1
          fi
        fi
        
        echo "ğŸ“‹ Using mochawesome combined report for evidence creation:"
        cat cypress-results.json
        
        jf evd create --release-bundle quotopia --release-bundle-version ${{ steps.get-latest-dev-version.outputs.latest_dev_version }} \
          --predicate cypress-results.json --markdown cypress-e2e-report.md --provider-id cypress --predicate-type https://cypress.io/evidence/e2e/v1
          

    - name: Upload Cypress Markdown Report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: cypress-e2e-report
        path: cypress-e2e-report.md
        retention-days: 30
        if-no-files-found: warn

    - name: Cleanup
      if: always()
      run: |
        # Clean up generated files and containers
        rm -f e2e-test-compose.yml cypress-results.json
        rm -rf e2e-tests/cypress/results/ 2>/dev/null || true
        docker compose -f e2e-test-compose.yml down -v 2>/dev/null || true
        docker system prune -f
        
